{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#simple_nvidia_smi_display:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "BhmapK2WGSdi",
        "outputId": "29ce171a-0fae-48ef-834d-2894ba18bcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-b55aa0f0a21d>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b55aa0f0a21d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    simple_nvidia_smi_display:\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eumL-i6MGctZ"
      },
      "outputs": [],
      "source": [
        "#cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpevv25gebBU",
        "outputId": "aeb236c9-6f75-4fb9-81e6-60943a828b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ],
      "source": [
        "cd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UTfqdyjUpkT",
        "outputId": "103d1b32-122d-4f2f-e8d4-28402278d250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env/MOFreinforce\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2h6n9HnVH8Q",
        "outputId": "5a53dad6-6260-4616-a67d-abfb975b9015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiYSJbL9cT6R",
        "outputId": "5956d1c3-b8d9-489d-fa78-8c0ff800a6ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3-venv python3.10-venv\n",
            "0 upgraded, 4 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 2,475 kB of archives.\n",
            "After this operation, 2,891 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.5 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.2 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.7 [5,718 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-venv amd64 3.10.6-1~22.04.1 [1,042 B]\n",
            "Fetched 2,475 kB in 0s (7,340 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 124565 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.7) ...\n",
            "Selecting previously unselected package python3-venv.\n",
            "Preparing to unpack .../python3-venv_3.10.6-1~22.04.1_amd64.deb ...\n",
            "Unpacking python3-venv (3.10.6-1~22.04.1) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.7) ...\n",
            "Setting up python3-venv (3.10.6-1~22.04.1) ...\n"
          ]
        }
      ],
      "source": [
        " !sudo apt install python3-venv -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcTyJ0L8dBH9"
      },
      "outputs": [],
      "source": [
        "mkdir pytorch_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9xcLOSddC10",
        "outputId": "bc186a46-617c-4d5c-e208-c87aa5de5a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env\n"
          ]
        }
      ],
      "source": [
        "cd pytorch_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x8wjYz9dGaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa106774-6098-4e3c-eedc-6e014073116f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Command '['/content/pytorch_env/pytorch_env/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n"
          ]
        }
      ],
      "source": [
        "!python3 -m venv pytorch_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHE2ds3jdHpS",
        "outputId": "fe0422b5-3303-419e-89b7-5dd9b96242ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10-venv is already the newest version (3.10.12-1~22.04.7).\n",
            "python3.10-venv set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install python3.10-venv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QpKGKKNdKqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7d4633-4a4b-4a9d-f8fb-09a012666fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: pytorch_env/bin/activate: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!source pytorch_env/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mofreinforce --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnJCdnZq6x9t",
        "outputId": "6de0a59b-ddd1-4332-ec8f-665e3c224dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mofreinforce\n",
            "  Using cached mofreinforce-1.0.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pytorch-lightning==1.8.0 (from mofreinforce)\n",
            "  Using cached pytorch_lightning-1.8.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting torchmetrics==0.9.0 (from mofreinforce)\n",
            "  Using cached torchmetrics-0.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting sacred>=0.8.2 (from mofreinforce)\n",
            "  Using cached sacred-0.8.7-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from mofreinforce) (1.26.4)\n",
            "Collecting sklearn>=0.0 (from mofreinforce)\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU0Aajr7DABR",
        "outputId": "9ae7e715-945a-4f01-fb35-4f1e96e4e558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.0)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.0\n",
            "    Uninstalling pip-24.0:\n",
            "      Successfully uninstalled pip-24.0\n",
            "Successfully installed pip-24.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqdItKJNdMe2",
        "outputId": "1ba2ecc1-d414-436d-f5a6-fe52a5765f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.13.0+cu117\n",
            "  Using cached https://download.pytorch.org/whl/cu117/torch-1.13.0%2Bcu117-cp311-cp311-linux_x86_64.whl (1807.2 MB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.0+cu116 (from versions: 0.1.6, 0.2.0, 0.15.0+cpu, 0.15.0+cu117, 0.15.0+cu118, 0.15.1, 0.15.1+cpu, 0.15.1+cu117, 0.15.1+cu118, 0.15.2, 0.15.2+cpu, 0.15.2+cu117, 0.15.2+cu118, 0.15.2+rocm5.3, 0.15.2+rocm5.4.2, 0.16.0, 0.16.0+cpu, 0.16.0+cu118, 0.16.0+cu121, 0.16.0+rocm5.5, 0.16.0+rocm5.6, 0.16.1, 0.16.1+cpu, 0.16.1+cu118, 0.16.1+cu121, 0.16.1+rocm5.5, 0.16.1+rocm5.6, 0.16.2, 0.16.2+cpu, 0.16.2+cu118, 0.16.2+cu121, 0.16.2+rocm5.5, 0.16.2+rocm5.6, 0.17.0, 0.17.0+cpu, 0.17.0+cu118, 0.17.0+cu121, 0.17.0+rocm5.6, 0.17.0+rocm5.7, 0.17.1, 0.17.1+cpu, 0.17.1+cu118, 0.17.1+cu121, 0.17.1+rocm5.6, 0.17.1+rocm5.7, 0.17.2, 0.17.2+cpu, 0.17.2+cu118, 0.17.2+cu121, 0.17.2+rocm5.6, 0.17.2+rocm5.7, 0.18.0, 0.18.0+cpu, 0.18.0+cu118, 0.18.0+cu121, 0.18.0+rocm5.7, 0.18.0+rocm6.0, 0.18.1, 0.18.1+cpu, 0.18.1+cu118, 0.18.1+cu121, 0.18.1+rocm5.7, 0.18.1+rocm6.0, 0.19.0, 0.19.1, 0.20.0, 0.20.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.0+cu116\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#!pip3 install torch==1.12.0+cu113 torchvision==0.14.0+cu113 torchaudio==0.12.0+cu113 --index-url https://download.pytorch.org/whl/cu113\n",
        "#!pip3 install torch==1.13.0+cu117 torchvision==0.15.0+cu117 torchaudio==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip3 install torch==1.13.0+cu117 torchvision==0.14.0+cu116 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mmTOqJJeF0V",
        "outputId": "b905ae5c-2286-42a6-f1a1-f8f07042c099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MOFreinforce'...\n",
            "remote: Enumerating objects: 434, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 434 (delta 8), reused 11 (delta 8), pack-reused 406 (from 1)\u001b[K\n",
            "Receiving objects: 100% (434/434), 15.23 MiB | 23.17 MiB/s, done.\n",
            "Resolving deltas: 100% (206/206), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hspark1212/MOFreinforce.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHfZBqsceM6g",
        "outputId": "7e46fae6-3503-4cf9-d292-dc886673fcbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env/MOFreinforce\n"
          ]
        }
      ],
      "source": [
        "cd MOFreinforce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U37fBs5esBO",
        "outputId": "2a346b9d-0d4c-4e68-bb7c-dba14e207484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip==24.0 in /usr/local/lib/python3.11/dist-packages (24.0)\n"
          ]
        }
      ],
      "source": [
        "!sudo pip install --upgrade pip==24.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1Xn_QlkeuoO",
        "outputId": "01be163c-c716-45ab-e5d9-84ae65e14bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wheels as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall wheels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install torchmetrics==1.5.0"
      ],
      "metadata": {
        "id": "nnaYHKzz_IPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlgOF3uHewaO",
        "outputId": "6f6eaf43-d34f-44c4-b2ac-1ba0d98f5e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/pytorch_env/MOFreinforce\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-lightning==1.7.7 (from mofreinforce==0.0.1)\n",
            "  Using cached pytorch_lightning-1.7.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting torch==1.13.1 (from mofreinforce==0.0.1)\n",
            "  Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchmetrics==1.5.0 (from mofreinforce==0.0.1)\n",
            "  Using cached torchmetrics-1.5.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting sacred (from mofreinforce==0.0.1)\n",
            "  Using cached sacred-0.8.7-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mofreinforce==0.0.1) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from mofreinforce==0.0.1) (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mofreinforce==0.0.1) (4.67.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from mofreinforce==0.0.1) (1.0.13)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from mofreinforce==0.0.1) (4.47.1)\n",
            "Collecting SmilesPE (from mofreinforce==0.0.1)\n",
            "  Using cached SmilesPE-0.0.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting rdkit (from mofreinforce==0.0.1)\n",
            "  Using cached rdkit-2024.9.4-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting wget (from mofreinforce==0.0.1)\n",
            "  Using cached wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from mofreinforce==0.0.1) (2.2.2)\n",
            "Collecting jupyterlab (from mofreinforce==0.0.1)\n",
            "  Using cached jupyterlab-4.3.4-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mofreinforce==0.0.1) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from mofreinforce==0.0.1) (0.13.2)\n",
            "Collecting ase (from mofreinforce==0.0.1)\n",
            "  Using cached ase-3.24.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.7.7->mofreinforce==0.0.1) (6.0.2)\n",
            "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.7->mofreinforce==0.0.1) (2024.10.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.7.7->mofreinforce==0.0.1) (2.17.1)\n",
            "Collecting pyDeprecate>=0.3.1 (from pytorch-lightning==1.7.7->mofreinforce==0.0.1)\n",
            "  Using cached pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.7.7->mofreinforce==0.0.1) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.7.7->mofreinforce==0.0.1) (4.12.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->mofreinforce==0.0.1)\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->mofreinforce==0.0.1)\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->mofreinforce==0.0.1)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->mofreinforce==0.0.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.5.0->mofreinforce==0.0.1)\n",
            "  Using cached lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->mofreinforce==0.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->mofreinforce==0.0.1) (0.45.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from ase->mofreinforce==0.0.1) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mofreinforce==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mofreinforce==0.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mofreinforce==0.0.1) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mofreinforce==0.0.1) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mofreinforce==0.0.1) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mofreinforce==0.0.1) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mofreinforce==0.0.1) (2.8.2)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->mofreinforce==0.0.1) (0.28.1)\n",
            "Collecting ipykernel>=6.5.0 (from jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->mofreinforce==0.0.1) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->mofreinforce==0.0.1) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->mofreinforce==0.0.1) (0.2.4)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->mofreinforce==0.0.1) (6.3.3)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab->mofreinforce==0.0.1) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->mofreinforce==0.0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->mofreinforce==0.0.1) (2024.2)\n",
            "Collecting docopt-ng<1.0,>=0.9 (from sacred->mofreinforce==0.0.1)\n",
            "  Using cached docopt_ng-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jsonpickle>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from sacred->mofreinforce==0.0.1) (4.0.1)\n",
            "Collecting munch<5.0,>=2.5 (from sacred->mofreinforce==0.0.1)\n",
            "  Using cached munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from sacred->mofreinforce==0.0.1) (1.17.0)\n",
            "Requirement already satisfied: py-cpuinfo>=4.0 in /usr/local/lib/python3.11/dist-packages (from sacred->mofreinforce==0.0.1) (9.0.0)\n",
            "Collecting colorama>=0.4 (from sacred->mofreinforce==0.0.1)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.11/dist-packages (from sacred->mofreinforce==0.0.1) (3.1.44)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->mofreinforce==0.0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->mofreinforce==0.0.1) (3.5.0)\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.11/dist-packages (from SmilesPE->mofreinforce==0.0.1) (1.0.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from SmilesPE->mofreinforce==0.0.1) (4.3.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->mofreinforce==0.0.1) (0.20.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->mofreinforce==0.0.1) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->mofreinforce==0.0.1) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->mofreinforce==0.0.1) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->mofreinforce==0.0.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->mofreinforce==0.0.1) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->mofreinforce==0.0.1) (0.21.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.7->mofreinforce==0.0.1) (3.11.11)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->mofreinforce==0.0.1) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->mofreinforce==0.0.1) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->mofreinforce==0.0.1) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->mofreinforce==0.0.1) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->mofreinforce==0.0.1) (0.14.0)\n",
            "Collecting comm>=0.1.1 (from ipykernel>=6.5.0->jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab->mofreinforce==0.0.1) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab->mofreinforce==0.0.1) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab->mofreinforce==0.0.1) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab->mofreinforce==0.0.1) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab->mofreinforce==0.0.1) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab->mofreinforce==0.0.1) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab->mofreinforce==0.0.1) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab->mofreinforce==0.0.1) (3.0.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->mofreinforce==0.0.1) (4.3.6)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached jupyter_events-0.11.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1) (7.16.5)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->mofreinforce==0.0.1) (1.8.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->mofreinforce==0.0.1) (2.16.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->mofreinforce==0.0.1)\n",
            "  Using cached json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->mofreinforce==0.0.1) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mofreinforce==0.0.1) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mofreinforce==0.0.1) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mofreinforce==0.0.1) (2.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.7->mofreinforce==0.0.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.7->mofreinforce==0.0.1) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.7->mofreinforce==0.0.1) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.7->mofreinforce==0.0.1) (4.25.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.7->mofreinforce==0.0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.7->mofreinforce==0.0.1) (3.1.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->SmilesPE->mofreinforce==0.0.1) (7.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython->sacred->mofreinforce==0.0.1) (4.0.12)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from timm->mofreinforce==0.0.1)\n",
            "  Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Using cached torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Using cached torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached torchvision-0.17.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "  Using cached torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting timm (from mofreinforce==0.0.1)\n",
            "  Using cached timm-1.0.13-py3-none-any.whl.metadata (53 kB)\n",
            "  Using cached timm-1.0.12-py3-none-any.whl.metadata (51 kB)\n",
            "  Using cached timm-1.0.11-py3-none-any.whl.metadata (48 kB)\n",
            "  Using cached timm-1.0.10-py3-none-any.whl.metadata (48 kB)\n",
            "  Using cached timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "  Using cached timm-1.0.8-py3-none-any.whl.metadata (53 kB)\n",
            "  Using cached timm-1.0.7-py3-none-any.whl.metadata (47 kB)\n",
            "  Using cached timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "  Using cached timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
            "  Using cached timm-0.9.11-py3-none-any.whl.metadata (60 kB)\n",
            "  Using cached timm-0.9.10-py3-none-any.whl.metadata (59 kB)\n",
            "  Using cached timm-0.9.9-py3-none-any.whl.metadata (59 kB)\n",
            "  Using cached timm-0.9.8-py3-none-any.whl.metadata (59 kB)\n",
            "  Using cached timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n",
            "  Using cached timm-0.9.6-py3-none-any.whl.metadata (58 kB)\n",
            "  Using cached timm-0.9.5-py3-none-any.whl.metadata (69 kB)\n",
            "  Using cached timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n",
            "  Using cached timm-0.9.1-py3-none-any.whl.metadata (68 kB)\n",
            "  Using cached timm-0.9.0-py3-none-any.whl.metadata (68 kB)\n",
            "  Using cached timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached timm-0.6.12-py3-none-any.whl.metadata (37 kB)\n",
            "  Using cached timm-0.6.11-py3-none-any.whl.metadata (36 kB)\n",
            "  Using cached timm-0.6.7-py3-none-any.whl.metadata (33 kB)\n",
            "  Using cached timm-0.6.5-py3-none-any.whl.metadata (45 kB)\n",
            "  Using cached timm-0.5.4-py3-none-any.whl.metadata (36 kB)\n",
            "  Using cached timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
            "  Using cached timm-0.4.9-py3-none-any.whl.metadata (27 kB)\n",
            "  Using cached timm-0.4.5-py3-none-any.whl.metadata (24 kB)\n",
            "  Using cached timm-0.3.4-py3-none-any.whl.metadata (20 kB)\n",
            "  Using cached timm-0.3.3-py3-none-any.whl.metadata (20 kB)\n",
            "  Using cached timm-0.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Using cached timm-0.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Using cached timm-0.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Using cached timm-0.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "  Using cached timm-0.1.30-py3-none-any.whl.metadata (37 kB)\n",
            "  Using cached timm-0.1.28-py3-none-any.whl.metadata (37 kB)\n",
            "  Using cached timm-0.1.26-py3-none-any.whl.metadata (39 kB)\n",
            "  Using cached timm-0.1.24-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached timm-0.1.22-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached timm-0.1.20-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached timm-0.1.18-py3-none-any.whl.metadata (34 kB)\n",
            "  Using cached timm-0.1.16-py3-none-any.whl.metadata (30 kB)\n",
            "  Using cached timm-0.1.14-py3-none-any.whl.metadata (20 kB)\n",
            "  Using cached timm-0.1.12-py3-none-any.whl.metadata (18 kB)\n",
            "  Using cached timm-0.1.10-py3-none-any.whl.metadata (18 kB)\n",
            "  Using cached timm-0.1.8-py3-none-any.whl.metadata (17 kB)\n",
            "  Using cached timm-0.1.6-py3-none-any.whl.metadata (16 kB)\n",
            "  Using cached timm-0.1.4-py3-none-any.whl.metadata (16 kB)\n",
            "  Using cached timm-0.1.2-py3-none-any.whl.metadata (16 kB)\n",
            "  Using cached timm-0.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "\u001b[31mERROR: Cannot install mofreinforce, mofreinforce==0.0.1, timm and torchvision==0.20.1+cu121 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.20.1+cu121 depends on torch==2.5.1\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.20.1 depends on torch==2.5.1\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.20.0 depends on torch==2.5.0\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.19.1 depends on torch==2.4.1\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.19.0 depends on torch==2.4.0\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.18.1 depends on torch==2.3.1\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.18.0 depends on torch==2.3.0\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.17.2 depends on torch==2.2.2\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.17.1 depends on torch==2.2.1\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.17.0 depends on torch==2.2.0\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.16.2 depends on torch==2.1.2\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.16.1 depends on torch==2.1.1\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.16.0 depends on torch==2.1.0\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.15.2 depends on torch==2.0.1\n",
            "    mofreinforce 0.0.1 depends on torch==1.13.1\n",
            "    pytorch-lightning 1.7.7 depends on torch>=1.9.*\n",
            "    torchmetrics 1.5.0 depends on torch>=1.10.0\n",
            "    timm 0.1.1 depends on torch>=1.0\n",
            "    torchvision 0.15.1 depends on torch==2.0.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGPWsTjfH4x8"
      },
      "outputs": [],
      "source": [
        "#cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHZ-W-DAfBto",
        "outputId": "00db66f3-59a3-4f7a-a31f-30835d921791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env/MOFreinforce/mofreinforce\n"
          ]
        }
      ],
      "source": [
        "cd mofreinforce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbk4o71efI4I",
        "outputId": "e62992f2-da66-4f3a-e0d2-3253fdd58e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics==0.9.3\n",
            "  Using cached torchmetrics-0.9.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==0.9.3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==0.9.3) (2.5.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchmetrics==0.9.3) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.9.3) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3.1->torchmetrics==0.9.3) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.1->torchmetrics==0.9.3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.1->torchmetrics==0.9.3) (3.0.2)\n",
            "Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.6/419.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics==0.9.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "_98oCr3HfLLc",
        "outputId": "142bd066-22e5-4868-fea5-7b7fd617fcde"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytorch_lightning'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7bbeaa081bfe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "print(pl.__version__)\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF1ezK5QFXMt"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWu94iR3FkxF",
        "outputId": "cd645030-b117-407b-dd61-797c9033da09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env/MOFreinforce\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFjTyMB9FlQB",
        "outputId": "7003fc7f-ece5-4e50-d9a6-9d8b82d03ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZDruO5jFlwE",
        "outputId": "be4d1d1f-b70d-4edd-b092-f03eb8fe58ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtzBhObMFmMp",
        "outputId": "8ef16f6e-b802-40f3-d5ff-33f73bb6b4c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMvywcFrFmt1",
        "outputId": "6a168d6a-dc6d-4c4d-fbbd-796ec0f15b92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard\n"
          ]
        }
      ],
      "source": [
        "cd usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElBldwdjFpCt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.remove(\"summary.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "wRmEnq8IFrRW",
        "outputId": "5059b0eb-5c63-4f96-d088-fc304b2e8cbf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ee6f0d07-d3b7-4d1c-b104-4557417e7866\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ee6f0d07-d3b7-4d1c-b104-4557417e7866\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving summary.py to summary.py\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yYZvfqfFtYv",
        "outputId": "be01ef6f-ab95-4f15-ac24-8bfd6eb449bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OWjJrdFFxy1",
        "outputId": "a921c967-f482-4357-c54d-35afc3a96bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5_bCFAPFyGZ",
        "outputId": "ec4f34f5-85d4-46f6-8f1c-96f413e57916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl-R5-rFFyhe",
        "outputId": "f8865d7d-debe-4320-afd9-153ce6a83e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxfBxdANFyyD",
        "outputId": "3e8fd42a-79d9-4d40-963f-4f752049c275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCXN3aEUFzVd",
        "outputId": "a161169a-04b2-4a29-ec72-dd90d46d0531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOkY6QYjFzxp",
        "outputId": "c6e1420f-93de-4c4f-e899-a5b5ae11b9ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug6PLVFxF0ut",
        "outputId": "fd80c67e-16ee-484e-fe7c-69a4d8922f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFJ1laMvF3KF",
        "outputId": "9aa1c428-608c-4650-9a23-f20b994b4b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env/MOFreinforce/mofreinforce\n"
          ]
        }
      ],
      "source": [
        "cd /content/pytorch_env/MOFreinforce/mofreinforce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM0CEfSdfTKi",
        "outputId": "b9dfa27d-7134-48d7-b782-d271b8ba81cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====Download basic data and pretrained models =============================================\n",
            "\n",
            "\n",
            "====Successfully download : /content/pytorch_env/MOFreinforce/mofreinforce/default.tar.gz=======================================\n",
            "\n",
            "\n",
            "====Unzip : basic data and pretrained models===============================================\n",
            "\n",
            "\n",
            "====Unzip successfully: basic data and pretrained models===============================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mofreinforce download default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTBQIm5IIx7H",
        "outputId": "c5f18885-a6a7-4541-e6ff-c34c7cb04bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env/MOFreinforce/mofreinforce/data/dataset_generator\n"
          ]
        }
      ],
      "source": [
        "cd data/dataset_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRdMxFwhgFX9",
        "outputId": "aa4631f5-6cf8-4b32-eb8f-90177abc1425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pytorch_env/MOFreinforce/mofreinforce\n"
          ]
        }
      ],
      "source": [
        "#cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPMDtptRKjQj"
      },
      "outputs": [],
      "source": [
        "# don't use cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRVhSo-qKfBs"
      },
      "outputs": [],
      "source": [
        "#cd content/pytorch_env/MOFreinforce/mofreinforce/data/dataset_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cGwU4N7KszK"
      },
      "outputs": [],
      "source": [
        "#os.remove(\"test.csv\") Do this manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTm76pM_KvxF"
      },
      "outputs": [],
      "source": [
        "#gen_test = files.upload() Do this manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbWm5VBOI0uQ"
      },
      "outputs": [],
      "source": [
        "#cd .. Do this manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWc1VXHjLHCI"
      },
      "outputs": [],
      "source": [
        "#cd dataset_reinforce do this manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYinD2Y_LLL0"
      },
      "outputs": [],
      "source": [
        "#os.remove(\"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Inegfq19LOHU"
      },
      "outputs": [],
      "source": [
        "#rei_test = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjO7NcTWI2Cy"
      },
      "outputs": [],
      "source": [
        "#cd content/MOFreinforce/mofreinforce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp84hkGwJCf-"
      },
      "outputs": [],
      "source": [
        "#cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpDQakOpIbRR"
      },
      "outputs": [],
      "source": [
        "#!zip -r MOFReinforce_data.zip\" . -i mofreinforce/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E15WCTjeJiyf"
      },
      "outputs": [],
      "source": [
        "#!zip -r /content/your_data.zip /mofreinforce/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2Ke2X7KL2fz",
        "outputId": "a472f8e0-8213-4be9-ad62-8ba4146205c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env/MOFreinforce/mofreinforce/data\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEOsSsxsL4LD",
        "outputId": "d57366d1-9215-4dce-a76f-74f46c62fdd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_env/MOFreinforce/mofreinforce\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWULwZyEgQ-G"
      },
      "source": [
        "##Pause Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7H2OK44gShV"
      },
      "outputs": [],
      "source": [
        "''' BReak\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8-Gm-TCe3gE",
        "outputId": "f7671b98-77cb-4f05-cb78-5ed39de048e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "WARNING - root - Added new config entry: \"__doc__\"\n",
            "WARNING - reinforce - No observers have been added to this run\n",
            "INFO - reinforce - Running command 'main'\n",
            "INFO - reinforce - Started\n",
            "Global seed set to 0\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
            "                not been set for this class (Scalar). The property determines if `update` by\n",
            "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
            "                achieved and we recommend setting this to `False`.\n",
            "                We provide an checking function\n",
            "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
            "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
            "                default for now) or if `full_state_update=False` can be used safely.\n",
            "                \n",
            "  warnings.warn(*args, **kwargs)\n",
            "load model : model/predictor/best_predictor_v0_qkh_round3.ckpt\n",
            "load model : model/generator/generator.ckpt\n",
            "Global seed set to 0\n",
            "load model : model/reinforce/best_v0_qkh_round3.ckpt\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "Global seed set to 0\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "read file : data/dataset_generator/test.csv, num_data : 20\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 2/2 [00:00<00:00, 138.76it/s]\n",
            "  0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 1/20 [00:01<00:29,  1.57s/it]\u001b[A\n",
            " 10% 2/20 [00:01<00:15,  1.14it/s]\u001b[Aconnection points error\n",
            "\n",
            " 15% 3/20 [00:02<00:10,  1.63it/s]\u001b[A\n",
            " 20% 4/20 [00:02<00:07,  2.11it/s]\u001b[A\n",
            " 25% 5/20 [00:02<00:05,  2.76it/s]\u001b[A\n",
            " 30% 6/20 [00:02<00:04,  3.36it/s]\u001b[A\n",
            " 35% 7/20 [00:03<00:03,  3.42it/s]\u001b[A\n",
            " 40% 8/20 [00:03<00:03,  3.17it/s]\u001b[A\n",
            " 45% 9/20 [00:04<00:04,  2.65it/s]\u001b[AThe last token is not [EOS]\n",
            "\n",
            " 50% 10/20 [00:05<00:06,  1.57it/s]\u001b[Aconnection points error\n",
            "\n",
            " 55% 11/20 [00:05<00:05,  1.55it/s]\u001b[A\n",
            " 60% 12/20 [00:06<00:04,  1.92it/s]\u001b[A\n",
            " 65% 13/20 [00:06<00:03,  2.31it/s]\u001b[Aconnection points error\n",
            "connection points error\n",
            "\n",
            " 75% 15/20 [00:06<00:01,  2.94it/s]\u001b[A\n",
            " 80% 16/20 [00:07<00:01,  3.28it/s]\u001b[A\n",
            " 85% 17/20 [00:07<00:00,  3.59it/s]\u001b[Aconnection points error\n",
            "\n",
            " 90% 18/20 [00:07<00:00,  3.89it/s]\u001b[Aconnection points error\n",
            "\n",
            " 95% 19/20 [00:07<00:00,  3.71it/s]\u001b[A\n",
            "100% 20/20 [00:08<00:00,  2.46it/s]\n",
            "2025-01-02 14:11:53.801537: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-02 14:11:53.819699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-02 14:11:53.841292: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-02 14:11:53.847680: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-02 14:11:53.863044: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-02 14:11:55.187579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "ERROR - reinforce - Failed after 0:00:15!\n",
            "Traceback (most recent calls WITHOUT Sacred internals):\n",
            "  File \"/content/pytorch_env/MOFreinforce/mofreinforce/run_reinforce.py\", line 93, in main\n",
            "    trainer.test(model, datamodule=dm)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 862, in test\n",
            "    return self._call_and_handle_interrupt(self._test_impl, model, dataloaders, ckpt_path, verbose, datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 648, in _call_and_handle_interrupt\n",
            "    return self.strategy.launcher.launch(trainer_fn, *args, trainer=self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/subprocess_script.py\", line 93, in launch\n",
            "    return function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 909, in _test_impl\n",
            "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1166, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1249, in _run_stage\n",
            "    return self._run_evaluate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1295, in _run_evaluate\n",
            "    eval_loop_results = self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\", line 207, in run\n",
            "    output = self.on_run_end()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 183, in on_run_end\n",
            "    self._evaluation_epoch_end(self._outputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 293, in _evaluation_epoch_end\n",
            "    self.trainer._call_lightning_module_hook(hook_name, output_or_outputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1550, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/content/pytorch_env/MOFreinforce/mofreinforce/reinforce/module.py\", line 243, in test_epoch_end\n",
            "    metrics = self.update_metrics(list_src, metrics, split)\n",
            "  File \"/content/pytorch_env/MOFreinforce/mofreinforce/reinforce/module.py\", line 335, in update_metrics\n",
            "    ol = metrics.gen_ol[i]\n",
            "IndexError: list index out of range\n",
            "\n",
            "Testing DataLoader 0: 100% 2/2 [00:11<00:00,  5.76s/it] \n"
          ]
        }
      ],
      "source": [
        "!python run_reinforce.py with v0_qkh_round3 log_dir=test test_only=True load_path=model/reinforce/best_v0_qkh_round3.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr0wv391e_-N",
        "outputId": "8f4e8692-08cb-4858-96ac-78aa58b46cae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t40PRJZuElyj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ase.io import read\n",
        "from ase.visualize.plot import plot_atoms\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import RDConfig\n",
        "sys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))\n",
        "import sascorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayLS9j9qEoCi"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['font.sans-serif'] = \"Arial\"\n",
        "plt.rcParams['font.family'] = \"sans-serif\"\n",
        "plt.rcParams[\"font.size\"] = 15\n",
        "plt.rcParams[\"xtick.major.size\"] = 0\n",
        "plt.rcParams[\"ytick.major.size\"] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZMCao6aEpvE"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_json = \"test/results_v0_qkh_round3_seed0_from_best_v0_qkh_round3.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "oUFR8gPnFPeV",
        "outputId": "756902db-af72-4940-9731-9297d28ad609"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'test/results_v0_qkh_round3_seed0_from_best_v0_qkh_round3.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-834b9dbca831>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_optimized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m ret = np.array( list(zip(*results_optimized[\"preds\"])) +\n\u001b[1;32m      3\u001b[0m     [\n\u001b[1;32m      4\u001b[0m         \u001b[0mresults_optimized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gen_topos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mresults_optimized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gen_mcs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test/results_v0_qkh_round3_seed0_from_best_v0_qkh_round3.json'"
          ]
        }
      ],
      "source": [
        "results_optimized = json.load(open(path_json))\n",
        "ret = np.array( list(zip(*results_optimized[\"preds\"])) +\n",
        "    [\n",
        "        results_optimized[\"gen_topos\"],\n",
        "        results_optimized[\"gen_mcs\"],\n",
        "        results_optimized[\"gen_sms\"],\n",
        "    ]\n",
        ").T\n",
        "len(ret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ4KN_W8SO4A",
        "outputId": "57114811-7204-4f66-e462-26b72e77a427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['-35.282711029052734' 'reo' 'N131'\n",
            "  '*C1=CC=C(C(OC)C(OC)C2=CC=C(C3=CC=C(C4=CC=C(*)C=C4OC)C=C3)C=C2)C=C1']\n",
            " ['-43.1660270690918' 'dmp' 'N520'\n",
            "  '*COC1=C(I)C=C(CCCC2=CC=C(C*)C3=CC=CC=C23)C=C1I']\n",
            " ['-13.000164985656738' 'nbo' 'N87' '*CCCCCC1=CC(I)=C(OC*)C(I)=C1']\n",
            " ['-47.44456481933594' 'bcu' 'N131' '*CCCC1=CC=C(*)C=C1']\n",
            " ['-9.225879669189453' 'dmp' 'N68' '*CCCCN1CCC(*)CC1']\n",
            " ['-44.128273010253906' 'bcu' 'N131' '*CCCCCCC1=CC(*)=CC(N2C=CN=C2)=C1']\n",
            " ['-35.67491149902344' 'bcu' 'N131'\n",
            "  '*C1=CN=C2N=C(C3=CC=CC4=C(*)C=CC=C34)C=NC2=N1']\n",
            " ['-42.56185531616211' 'scu' 'N229'\n",
            "  '*CN1CCCN(C*)CCN(CC2=C(Cl)C(Cl)=C(*)C(Cl)=C2Cl)CCCN(C*)CC1']\n",
            " ['-20.0179500579834' 'dmp' 'N395' '*C1=CC(O)=CC(C(O)C(*)O)=C1']\n",
            " ['-41.914249420166016' 'crb' 'N520' '*C1=CC(*)=CC(C(C)(C)C)=C1']\n",
            " ['-36.91830825805664' 'lvt' 'N520' '*CCCCCCCC1=CC=C(*)C=C1']\n",
            " ['-37.00754165649414' 'sra' 'N520' '*CCCC1=CC(C)=C(*)C=C1C']\n",
            " ['-44.055782318115234' 'lon' 'N520'\n",
            "  '*CC1=C(F)C(F)=C(CC(=O)C2=CC=C(*)C=C2)C(F)=C1F']\n",
            " ['-38.29328155517578' 'qtz' 'N520'\n",
            "  '*CC1=C(C)C(C)=C(CCN2CCN(C*)CC2)C(C)=C1C']\n",
            " ['-37.41853332519531' 'dmp' 'N276'\n",
            "  '*C1C2CC3CC(C2)CC(CC(O)C4CC5CCN4CC5*)(C3)C1']\n",
            " ['-14.987720489501953' 'srs' 'N246' '*CNCC1=C(Cl)C(Cl)=C(*)C(Cl)=C1Cl']\n",
            " ['-27.48248291015625' 'dmp' 'N32' '*C/C=C/CNC1=CC=C(*)C=C1']\n",
            " ['-44.31953430175781' 'dmp' 'N520'\n",
            "  '*CC12CC3CC(C1)CC(CC4=CC(*)=CC(Br)=C4)(C3)C2']\n",
            " ['-46.47540283203125' 'bcg' 'N131'\n",
            "  '*COC1=C(I)C=C(CCC2=CC(*)=CC(C(C)(C)C)=C2)C=C1I']\n",
            " ['-32.95050048828125' 'tfz-d' 'N331' '*CC(*)CC1=NC(C)=C(*)S1']\n",
            " ['-43.557151794433594' 'cag' 'N520'\n",
            "  '*C1=CC(C)=C(C2=C(C)C=C(C(F)(F)C(*)(F)F)C=C2C)C(C)=C1']\n",
            " ['-24.302875518798828' 'cds' 'N445'\n",
            "  '*C1=C(C(C)C)C=C(C2CCC(*)CC2)C=C1C(C)C']\n",
            " ['-32.05201721191406' 'gra' 'N482'\n",
            "  '*CC1=CC(C*)=CC(CC=2SC=3SC(*)=C(C)C=3C=2C)=C1']\n",
            " ['-38.984214782714844' 'dmp' 'N520' '*CCCCCCC1C=CN(C*)N=N1']\n",
            " ['-11.570321083068848' 'lon' 'N435'\n",
            "  '*C1CN2CCC1CC2C(O)C34CC5CC(CC(*)(C5)C3)C4']\n",
            " ['-20.073749542236328' 'sod' 'N158' '*C1=CC(C)=CC(C(F)(F)C(*)(F)F)=C1']\n",
            " ['-23.403453826904297' 'reo' 'N352'\n",
            "  '*C#CC#CC#CCC1=C(F)C(F)=C(C*)C(F)=C1F']\n",
            " ['-34.875526428222656' 'csq' 'N374'\n",
            "  '*C1=CC(*)=CC(C#CC2=CC(*)=CC(C=3SC=4SC(*)=C(C)C=4C=3C)=C2)=C1']\n",
            " ['-48.11807632446289' 'dmp' 'N520'\n",
            "  '*CC1=C(F)C(F)=C(CC2=CC(Cl)=C(*)C=C2Cl)C(F)=C1F']\n",
            " ['-15.946236610412598' 'reo' 'N64' '*CCC1=CC(I)=C(OC*)C(I)=C1']\n",
            " ['-43.698455810546875' 'dmp' 'N520'\n",
            "  '*C1=CC(OC)=CC(C=2SC(*)=C3C=2OCCO3)=C1']\n",
            " ['-23.917640686035156' 'flu' 'N199'\n",
            "  '*C(=O)OCC(COC(*)=O)(COC(*)=O)COC(=O)C1=CC(*)=CC(N2C=CN=C2)=C1']\n",
            " ['-38.96403503417969' 'dmp' 'N520'\n",
            "  '*C1=CC(Br)=CC(C2=CC=C(S(=O)(=O)OC3=CC(*)=CC=C3OC)C=C2)=C1']\n",
            " ['-43.99290084838867' 'lvt' 'N520'\n",
            "  '*C1=CC(Br)=CC(C2=CC(Cl)=C(*)C=C2Cl)=C1']\n",
            " ['-23.933074951171875' 'scu' 'N171'\n",
            "  '*CSC1=NN=C(CCC2=NN=C(SCC3=CC4=CC5=CC(*)=C(*)C=C5C=C4C=C3*)N2N)N1N']\n",
            " ['-40.420204162597656' 'dmp' 'N520' '*C#CCC1=CC=C(*)C=C1']\n",
            " ['-15.987008094787598' 'pcu' 'N593'\n",
            "  '*CC1=C(C)C(C)=C(CC2=NC(C)=C(*)S2)C(C)=C1C']\n",
            " ['-35.956668853759766' 'cds' 'N520'\n",
            "  '*COC1=CC=C(OCC2=CC(*)=CC(C(C)(C)C)=C2)C=C1']\n",
            " ['-19.988800048828125' 'dmc' 'N161' '*C1=CC(*)=CC(C(F)(F)C(*)(F)F)=C1']\n",
            " ['-41.80854034423828' 'dmp' 'N520' '*C#CC1=CC(*)=CC(C)=C1']\n",
            " ['-56.466796875' 'tfz-d' 'N131'\n",
            "  '*C(=O)OC1=CC(OC(*)=O)=CC(OC(=O)C2=CC(Cl)=C(*)C=C2Cl)=C1']\n",
            " ['-42.028472900390625' 'reo' 'N131'\n",
            "  '*C1=C(C)C(C)=C(C2=NN=C(*)N2N)C(C)=C1C']\n",
            " ['-41.29559326171875' 'reo' 'N131' '*CC1=CC=C(CC(O)C(*)O)C=C1']\n",
            " ['-35.58274459838867' 'tfz-d' 'N329'\n",
            "  '*C1=CC=C2C(=C1)C(CC)(CC)C3=C2C4=C(C5=C3C6=CC=C(C7=CC=CC8=C(*)C=CC=C78)C=C6C5(CC)CC)C9=CC=C(*)C=C9C4(CC)CC']\n",
            " ['-15.966073989868164' 'sxb' 'N602'\n",
            "  '*COC1=C(I)C=C(CCCC2=CC=C(C*)C3=CC=CC=C23)C=C1I']\n",
            " ['-31.19135856628418' 'reo' 'N331' '*C1=CC(OC)=CC(C(F)(F)C(*)(F)F)=C1']\n",
            " ['-50.213584899902344' 'tfz-d' 'N131'\n",
            "  '*CCCCCCN1C=C2C3=CN(*)C=C3C4=CN(*)C=C4C2=C1']\n",
            " ['-22.469118118286133' 'dmp' 'N342'\n",
            "  '*CC1=C(F)C(F)=C(CC2=CC=C(*)S2)C(F)=C1F']\n",
            " ['-10.626448631286621' 'sra' 'N76'\n",
            "  '*1C=C2C=C(C3=CC=C(CC(*)N)C=C3)OC=C2OCC(OC)=C1']\n",
            " ['-31.096960067749023' 'scu' 'N374'\n",
            "  '*C(=O)OCC(COC(*)=O)(COC(*)=O)COC(=O)C1CCC(*)(C)C1(C)C']\n",
            " ['-36.922698974609375' 'dmp' 'N215' '*CCCC1=C(F)C(F)=C(C*)C(F)=C1F']\n",
            " ['-20.349407196044922' 'reo' 'N217' '*CCCCC1=CC=C(C*)C2=CC=CC=C12']\n",
            " ['-41.36288833618164' 'nbo' 'N520'\n",
            "  '*C1=CC=C2C=CC(C(F)(F)C(*)(F)F)=CC2=C1']\n",
            " ['-25.507110595703125' 'utk' 'N606'\n",
            "  '*1CC23CCCC(C2)CC(CC(F)(F)C(*)(F)F)(C3)C1']\n",
            " ['-29.48072624206543' 'scu' 'N67'\n",
            "  '*C1=CC(*)=CC(/N=N/C2=CC(*)=CC(C3=CC=C4C(=C3)OC5=CC(*)=CC=C54)=C2)=C1']\n",
            " ['-25.166091918945312' 'srs' 'N440' '*CNCCC1=CC=CC(C*)=C1']\n",
            " ['-24.663883209228516' 'reo' 'N337' '*CCCCCCCCC1=C(F)C(F)=C(C*)C(F)=C1F']\n",
            " ['-21.261404037475586' 'hex' 'N141' '*CCCC1=C(C)C(C)=C(*)C(C)=C1C']\n",
            " ['-32.263336181640625' 'nbo' 'N520'\n",
            "  '*NCCCCCCNC1=CC=C2C(=C1)S(=O)(=O)C3=CC(*)=CC=C32']\n",
            " ['-8.629181861877441' 'qtz' 'N158'\n",
            "  '*CCCCCCSC1=NN=C(CCC2=NN=C(SC*)N2N)N1N']\n",
            " ['-35.55371856689453' 'cds' 'N520' '*C#CC12C=CC(C#CCCC*)(C=C1)C=C2']\n",
            " ['-54.17597198486328' 'bcu' 'N131'\n",
            "  '*CC1=C(F)C(F)=C(CC2=C(Br)C(Br)=C(*)C(Br)=C2Br)C(F)=C1F']\n",
            " ['-17.99371337890625' 'acs' 'N232' '*C1=CC(OC)=CC(C2=CC=C(*)N=C2)=C1']\n",
            " ['-27.086715698242188' 'srs' 'N499' '*C1=CC(Br)=CC(C(F)(F)C(*)(F)F)=C1']\n",
            " ['-10.8385009765625' 'pcu' 'N518'\n",
            "  '*C#CC12C3C4C1C5C2C3C45C#CC6=CC(Cl)=C(*)C=C6Cl']\n",
            " ['-14.318229675292969' 'pcu' 'N16' '*CCCCCC1=CC(*)=CC(OC)=C1']\n",
            " ['-39.44036865234375' 'cds' 'N520'\n",
            "  '*CC12CC3CC(C1)CC(CC4=CC(O)=C(*)C=C4O)(C3)C2']\n",
            " ['-41.131263732910156' 'gis' 'N520' '*C1=CC(Br)=CC(C2=CN(*)N=N2)=C1']\n",
            " ['-51.95610427856445' 'scu' 'N131' '*CC(*)CC1=NC(*)=NC(*)=N1']\n",
            " ['-36.13595199584961' 'hex' 'N131'\n",
            "  '*C1=CC=C(C2=CC=C(C3=CC=C(C4=CC(*)=CC(O)=C4)C=C3)C=C2)C=C1']\n",
            " ['-15.401262283325195' 'pcu' 'N106'\n",
            "  '*C1=CC(Br)=CC(C2=CC=C(C3=CC=C(*)S3)S2)=C1']\n",
            " ['-53.658058166503906' 'scu' 'N131'\n",
            "  '*C1=CC(C2=NN=C(*)N2N)=CC(C3=CN(C4=CC(*)=CC(*)=C4)N=N3)=C1']\n",
            " ['-41.185081481933594' 'bcu' 'N131' '*CCN1CCN(CCC2CCC(*)CC2)CC1']\n",
            " ['-10.63036823272705' 'qtz' 'N395' '*NCCCCCCNCC1=CC=C(*)C=C1']\n",
            " ['-26.40993881225586' 'fsc' 'N590'\n",
            "  '*C1=CC=C2C(=C1)C(C)(C)C3=C2C4=C(C5=C3C6=CC=C(C7=CC(*)=NC(*)=C7)C=C6C5(C)C)C8=CC=C(*)C=C8C4(C)C']\n",
            " ['-25.100120544433594' 'dmp' 'N156'\n",
            "  '*C#CC#CC#CC12C3=CC=CC=C3C(*)(C4=CC=CC=C41)C5=CC=CC=C52']\n",
            " ['-55.3031005859375' 'tfz-d' 'N131'\n",
            "  '*COC1=CC2=C(C=C1OC)CC3=CC(OCC4=C(I)C(*)=C(I)C(N)=C4I)=C(OC)C=C3CC5=CC(OC*)=C(OC)C=C5C2']\n",
            " ['-37.95392990112305' 'crs' 'N135'\n",
            "  '*CC1=C(F)C(F)=C(CC(F)(F)C(*)(F)F)C(F)=C1F']\n",
            " ['-22.933269500732422' 'crb' 'N697'\n",
            "  '*C1=CC(O)=CC(C2=CC=C3C(=C2)OC4=CC(*)=CC=C43)=C1']\n",
            " ['-10.188830375671387' 'cds' 'N631'\n",
            "  '*COC1=C(I)C=C(CCC2=NN=C(*)N=N2)C=C1I']\n",
            " ['-45.339813232421875' 'dmp' 'N520' '*C1=CC(Br)=CC(C2=NC(C)=C(*)S2)=C1']\n",
            " ['-16.95166778564453' 'bnn' 'N133'\n",
            "  '*C1=CC(Br)=CC(C2=C(F)C(F)=C(*)C(F)=C2F)=C1']\n",
            " ['-53.59171676635742' 'tfz-d' 'N131'\n",
            "  '*C(=O)OC1=CC(OC(*)=O)=CC(OC(=O)C2=NN=C(C#CC3=NN=C(*)N=N3)N=N2)=C1']\n",
            " ['-37.83673858642578' 'dmp' 'N520'\n",
            "  '*CSC1=NN=C(CCC2=NN=C(SCC3=CC=C(*)C=C3)N2N)N1N']\n",
            " ['-20.968603134155273' 'lcy' 'N589'\n",
            "  '*C1=CC(Br)=CC(C2CCC(*)(C)C2(C)C)=C1']\n",
            " ['-37.33803939819336' 'dia' 'N520' '*CC1=CC=C(CC2=CC(C)=C(*)C=C2C)C=C1']\n",
            " ['-34.10331726074219' 'tfz-d' 'N318'\n",
            "  '*CCCC1=CC=C(C(O)(C2=CC=C(*)C=C2)C3=CC=C(*)C=C3)C=C1']\n",
            " ['-41.888031005859375' 'dmp' 'N520'\n",
            "  '*C1=CC(O)=C(C2=CC(O)=C(*)C=C2O)C=C1O']\n",
            " ['-53.96588134765625' 'csq' 'N131'\n",
            "  '*C(=O)OCC(COC(*)=O)(COC(*)=O)COC(=O)C1=CC=C(C(OC)C(OC)C2=CC=C(*)C=C2)C=C1']\n",
            " ['-15.571122169494629' 'crs' 'N559'\n",
            "  '*C1=CC=C(O/C=C/OC2=CC=C(*)C=C2)C=C1']\n",
            " ['-44.36098098754883' 'dmp' 'N520' '*CCC1=CC(*)=CC(OC)=C1']\n",
            " ['-37.99906921386719' 'dmp' 'N520'\n",
            "  '*CSC1=NN=C(CCC2=NN=C(SCC3=C4C=CC=CC4=C(*)C5=CC=CC=C35)N2N)N1N']\n",
            " ['-30.508098602294922' 'gra' 'N482'\n",
            "  '*CC1=CC=C(CC2=C(C)C(*)=C(C)C(*)=C2C)C3=CC=CC=C13']\n",
            " ['-40.6025390625' 'bcu' 'N131'\n",
            "  '*NC(=O)C1=CC=C(C(=O)NC2=CC(*)=CC(C)=C2)C=C1']\n",
            " ['-32.52660369873047' 'reo' 'N226'\n",
            "  '*C1=CC(C)=C(C2=CC(C(C)C)=C(*)C(C(C)C)=C2)CC(C)=C1']\n",
            " ['-18.62553596496582' 'hex' 'N166'\n",
            "  '*C1=CC(C)=C(C2=C(C)C=C(C3=CC=4SC=5C=C(*)SC=5C=4S3)C=C2C)C(C)=C1']\n",
            " ['-38.8138313293457' 'dmp' 'N520' '*CCCCCCN1CCN(C*)CC1']]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(97, 4)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(ret)\n",
        "ret.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTXmuNwrFMi1"
      },
      "outputs": [],
      "source": [
        "top_n = 500\n",
        "ret = np.unique(ret, axis=0)\n",
        "sorted_ret = ret[np.argsort(ret[:, 0].astype(float))][:top_n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh-x0kbKX_lG"
      },
      "outputs": [],
      "source": [
        "!pip install pormake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdfxPFbWFNzv"
      },
      "outputs": [],
      "source": [
        "import pormake as pm\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "pm.log.disable_print()\n",
        "pm.log.disable_file_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHxJG0lbqOmI"
      },
      "outputs": [],
      "source": [
        "save_dir_bb = \"results/qkh/bb_dir\"\n",
        "save_dir_gen_mofs = \"results/qkh/gen_mofs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH_Y5mdBqQB1"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(save_dir_bb):\n",
        "    shutil.rmtree(save_dir_bb)\n",
        "shutil.copytree(f\"{pm.__path__[0]}/database/bbs\", save_dir_bb)\n",
        "# bb_dir\n",
        "database = pm.Database(bb_dir=Path(save_dir_bb))\n",
        "# save_dir for generated MOFs\n",
        "os.makedirs(save_dir_gen_mofs, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-XBttPJqR_R"
      },
      "outputs": [],
      "source": [
        "def smiles_to_xyz(smiles, save_dir, bb_name=\"tmp\"):\n",
        "    # smiles to mol\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    # mol to 3D mol\n",
        "    m = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(m)\n",
        "    AllChem.MMFFOptimizeMolecule(m)\n",
        "    # mol to molblock\n",
        "    mol_block = Chem.MolToMolBlock(m)\n",
        "    lines = mol_block.splitlines()\n",
        "    # write xyz file\n",
        "    line = lines[3]\n",
        "    num_atoms = int(line[:3])\n",
        "    num_bonds = int(line[3:6])\n",
        "\n",
        "    save_path = os.path.join(save_dir, f\"{bb_name}.xyz\")\n",
        "    with open(save_path, \"w\") as f:\n",
        "        f.write(f\"{num_atoms}\\n\")\n",
        "        f.write(f\"mol to xyz file\\n\")\n",
        "        # coords\n",
        "        for line in lines[4:4+num_atoms]:\n",
        "            tokens = line.split()\n",
        "            # change dummy atoms R to X\n",
        "            if tokens[3] == \"R\":\n",
        "                tokens[3] = \"X\"\n",
        "            f.write(f\"{tokens[3]:<10}    {tokens[0]:<10}    {tokens[1]:<10}    {tokens[2]:<10}\\n\")\n",
        "        # bonds\n",
        "        for line in lines[4+num_atoms:4+num_atoms+num_bonds]:\n",
        "            tokens = [int(line[:3]), int(line[3:6]), int(line[6:9])]\n",
        "            # bond type\n",
        "            if tokens[2] == 1:\n",
        "                bond_type = \"S\"\n",
        "            elif tokens[2] == 2:\n",
        "                bond_type = \"D\"\n",
        "            elif tokens[2] == 3:\n",
        "                bond_type = \"T\"\n",
        "            elif tokens[2] == 4:\n",
        "                bond_type = \"A\"\n",
        "            else:\n",
        "                raise Exception(\"bond type error\")\n",
        "            # find index of atom\n",
        "            idx_1 = int(tokens[0]) - 1\n",
        "            idx_2 = int(tokens[1]) - 1\n",
        "            f.write(f\"{idx_1:<10}{idx_2:<6}{bond_type:<6}\\n\")\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugAbO1klqguI"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyvW0YJaqT4X"
      },
      "outputs": [],
      "source": [
        "def construct_mofs(final_ret, save_dir_bb, save_dir_gen_mofs):\n",
        "    e0 = 0 # build error\n",
        "    e1 = 0\n",
        "    e2 = 0\n",
        "    e3 = 0\n",
        "    e4 = 0\n",
        "\n",
        "    # Create a csv.writer object\n",
        "    # Write data to the CSV file\n",
        "    CIFCreate = []\n",
        "    idx = 0\n",
        "    vocab_sm = {}\n",
        "    for p, topo_, mc_, sm_ in tqdm(final_ret):\n",
        "        print(p, topo_, mc_, sm_)\n",
        "        # save smiles to xyz file\n",
        "        try:\n",
        "            if sm_ not in vocab_sm.keys():\n",
        "                smiles_to_xyz(sm_, save_dir=save_dir_bb, bb_name=f\"{len(vocab_sm)}\")\n",
        "                vocab_sm[sm_] = f\"{len(vocab_sm)}\"\n",
        "        except Exception as e:\n",
        "            e0 += 1\n",
        "            print(\"The smile of organice linker can't be converted to xyz files\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        # get topo, mc, ol\n",
        "        topo = database.get_topo(topo_)\n",
        "        mc = database.get_bb(mc_)\n",
        "        ol = database.get_bb(vocab_sm[sm_])\n",
        "\n",
        "        # check connection point matching\n",
        "        topo_cn = list(topo.unique_cn)\n",
        "        if len(topo_cn) == 1:\n",
        "            topo_cn.append(2)\n",
        "        mc_cn = mc.n_connection_points\n",
        "        ol_cn = sm_.count(\"*\")\n",
        "\n",
        "        if set(topo_cn) != set([mc_cn, ol_cn]):\n",
        "            print(f\"fail : {topo_cn, mc_cn, ol_cn}\")\n",
        "            continue\n",
        "\n",
        "        # assingn node and edge\n",
        "        if mc_cn == topo_cn[0] and topo_cn[1] == 2:\n",
        "            node_bbs = {\n",
        "                0 : mc,\n",
        "            }\n",
        "            edge_bbs = {\n",
        "                tuple(topo.unique_edge_types[0]) : ol,\n",
        "            }\n",
        "        elif mc_cn == topo_cn[0] and topo_cn[1] != 2:\n",
        "            node_bbs = {\n",
        "                0 : mc,\n",
        "                1 : ol,\n",
        "            }\n",
        "            edge_bbs = {}\n",
        "        else:\n",
        "            node_bbs = {\n",
        "                0 : ol,\n",
        "                1 : mc,\n",
        "            }\n",
        "            edge_bbs = {}\n",
        "        # build MOF\n",
        "        builder = pm.Builder()\n",
        "        try:\n",
        "            gen_mof = builder.build_by_type(topology=topo, node_bbs=node_bbs, edge_bbs=edge_bbs)\n",
        "        except Exception as e:\n",
        "            e0 += 1\n",
        "            continue\n",
        "\n",
        "        # check criterion\n",
        "        # (1) SAscore < 6\n",
        "        m = Chem.MolFromSmiles(sm_)\n",
        "        score = sascorer.calculateScore(m)\n",
        "        if score > 6:\n",
        "            e1 += 1\n",
        "            continue\n",
        "        # (2) rmsd\n",
        "        if gen_mof.info[\"max_rmsd\"] > 0.3:\n",
        "            e2 += 1\n",
        "            continue\n",
        "        # (3) # of atoms <= 3000\n",
        "        if len(gen_mof.atoms) > 3000:\n",
        "            e3 += 1\n",
        "            continue\n",
        "        # (4) length of cells < 60 A\n",
        "        if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
        "            e4 += 1\n",
        "            continue\n",
        "\n",
        "        # write cif\n",
        "        try:\n",
        "            filename = f\"{str(idx).zfill(3)}_{topo_}+{mc_}+{vocab_sm[sm_]}.cif\"\n",
        "            dataname = f\"{str(idx).zfill(3)}_{topo_}+{mc_}+{vocab_sm[sm_]}\"\n",
        "            print(f\"write_cif {filename}\")\n",
        "            gen_mof.write_cif(f\"{save_dir_gen_mofs}/{filename}\")\n",
        "            idx += 1\n",
        "\n",
        "            CIFCreate.append(dataname)\n",
        "\n",
        "        except:\n",
        "            e0 += 1\n",
        "    # write vocab for smiles of organice linker\n",
        "    json.dump(vocab_sm, open(f\"{save_dir_gen_mofs}/vocab_sm.json\", \"w\"))\n",
        "    csv_file_path = 'data.csv'\n",
        "    df = pd.DataFrame(CIFCreate)\n",
        "    df.to_csv(csv_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOb-sheSt02G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8t4HGWoqXDR"
      },
      "outputs": [],
      "source": [
        "final_ret = sorted_ret[:100]\n",
        "construct_mofs(final_ret, save_dir_bb, save_dir_gen_mofs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WShUpgCU0i4Z"
      },
      "outputs": [],
      "source": [
        "cd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvxSwV_V0lXF"
      },
      "outputs": [],
      "source": [
        "cd /content/pytorch_env/MOFreinforce/mofreinforce/results/qkh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIS1aRQ60odc"
      },
      "outputs": [],
      "source": [
        "!zip -r qkh_Updated.zip gen_mofs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P7SKhQw0xXA"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('qkh_Updated.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ghb2gQLOQWg"
      },
      "outputs": [],
      "source": [
        "files.download('data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02SOo6j4gW7P"
      },
      "source": [
        "# Return #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wmlhOsUAgawy",
        "outputId": "99673947-662a-496d-edaa-6f0f8b283a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "WARNING - root - Added new config entry: \"__doc__\"\n",
            "WARNING - reinforce - No observers have been added to this run\n",
            "INFO - reinforce - Running command 'main'\n",
            "INFO - reinforce - Started\n",
            "Global seed set to 0\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
            "                not been set for this class (Scalar). The property determines if `update` by\n",
            "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
            "                achieved and we recommend setting this to `False`.\n",
            "                We provide an checking function\n",
            "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
            "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
            "                default for now) or if `full_state_update=False` can be used safely.\n",
            "                \n",
            "  warnings.warn(*args, **kwargs)\n",
            "load model : model/predictor/best_predictor_v0_qkh_round3.ckpt\n",
            "load model : model/generator/generator.ckpt\n",
            "Global seed set to 0\n",
            "load model : model/reinforce/best_v0_qkh_round3.ckpt\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "Global seed set to 0\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Missing logger folder: test/v0_qkh_round3_seed0_from_best_v0_qkh_round3\n",
            "read file : data/dataset_generator/test.csv, num_data : 20\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 2/2 [00:00<00:00, 180.19it/s]\n",
            "  0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 1/20 [00:01<00:27,  1.44s/it]\u001b[A\n",
            " 10% 2/20 [00:01<00:13,  1.35it/s]\u001b[A\n",
            " 15% 3/20 [00:01<00:08,  1.91it/s]\u001b[A\n",
            " 20% 4/20 [00:02<00:08,  2.00it/s]\u001b[A\n",
            " 25% 5/20 [00:02<00:06,  2.24it/s]\u001b[A\n",
            " 30% 6/20 [00:03<00:05,  2.43it/s]\u001b[A\n",
            " 35% 7/20 [00:03<00:05,  2.43it/s]\u001b[Aconnection points error\n",
            "\n",
            " 40% 8/20 [00:03<00:04,  2.51it/s]\u001b[A\n",
            " 45% 9/20 [00:04<00:04,  2.71it/s]\u001b[A\n",
            " 50% 10/20 [00:04<00:04,  2.43it/s]\u001b[A\n",
            " 55% 11/20 [00:04<00:03,  2.79it/s]\u001b[A\n",
            " 60% 12/20 [00:05<00:02,  2.78it/s]\u001b[A\n",
            " 65% 13/20 [00:05<00:02,  3.28it/s]\u001b[A\n",
            " 70% 14/20 [00:05<00:01,  3.66it/s]\u001b[A\n",
            " 75% 15/20 [00:05<00:01,  3.67it/s]\u001b[A\n",
            " 80% 16/20 [00:06<00:01,  3.52it/s]\u001b[A\n",
            " 85% 17/20 [00:06<00:00,  3.56it/s]\u001b[ASELFIES error\n",
            "\n",
            " 90% 18/20 [00:06<00:00,  3.60it/s]\u001b[A\n",
            " 95% 19/20 [00:07<00:00,  3.57it/s]\u001b[A\n",
            "100% 20/20 [00:07<00:00,  2.73it/s]\n",
            "2025-01-12 15:15:35.707032: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-12 15:15:35.725699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-12 15:15:35.746958: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-12 15:15:35.753393: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-12 15:15:35.768946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-12 15:15:37.143702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:535: PossibleUserWarning: It is recommended to use `self.log('test/conn_match', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:535: PossibleUserWarning: It is recommended to use `self.log('test/unique_ol', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:535: PossibleUserWarning: It is recommended to use `self.log('test/unique_topo_mc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:535: PossibleUserWarning: It is recommended to use `self.log('test/scaffold', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:535: PossibleUserWarning: It is recommended to use `self.log('test/total_reward', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:535: PossibleUserWarning: It is recommended to use `self.log('test/reward_0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:535: PossibleUserWarning: It is recommended to use `self.log('test/target_0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:535: PossibleUserWarning: It is recommended to use `self.log('test/num_fail', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
            "  warning_cache.warn(\n",
            "Testing DataLoader 0: 100% 2/2 [00:10<00:00,  5.50s/it] \n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m     test/conn_match     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      test/num_fail      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      test/reward_0      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6190502643585205    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      test/scaffold      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3888888955116272    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      test/target_0      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -37.14301681518555    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m    test/total_reward    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6190502643585205    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     test/unique_ol      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8888888955116272    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m   test/unique_topo_mc   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7222222089767456    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "INFO - reinforce - Completed after 0:00:15\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Collecting pormake\n",
            "  Downloading pormake-0.2.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: ase<4.0.0,>=3.22.1 in /usr/local/lib/python3.10/dist-packages (from pormake) (3.24.0)\n",
            "Requirement already satisfied: jax<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from jax[cpu]<0.5.0,>=0.4.1->pormake) (0.4.33)\n",
            "Requirement already satisfied: networkx<4.0,>=3.1 in /usr/local/lib/python3.10/dist-packages (from pormake) (3.4.2)\n",
            "Collecting pymatgen<2024.0.0,>=2023.8.10 (from pormake)\n",
            "  Downloading pymatgen-2023.12.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from ase<4.0.0,>=3.22.1->pormake) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ase<4.0.0,>=3.22.1->pormake) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from ase<4.0.0,>=3.22.1->pormake) (3.10.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax<0.5.0,>=0.4.1->jax[cpu]<0.5.0,>=0.4.1->pormake) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax<0.5.0,>=0.4.1->jax[cpu]<0.5.0,>=0.4.1->pormake) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax<0.5.0,>=0.4.1->jax[cpu]<0.5.0,>=0.4.1->pormake) (3.4.0)\n",
            "Collecting monty>=3.0.2 (from pymatgen<2024.0.0,>=2023.8.10->pormake)\n",
            "  Downloading monty-2025.1.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting palettable>=3.1.1 (from pymatgen<2024.0.0,>=2023.8.10->pormake)\n",
            "  Downloading palettable-3.3.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pymatgen<2024.0.0,>=2023.8.10->pormake) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from pymatgen<2024.0.0,>=2023.8.10->pormake) (5.24.1)\n",
            "Collecting pybtex (from pymatgen<2024.0.0,>=2023.8.10->pormake)\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pymatgen<2024.0.0,>=2023.8.10->pormake) (2.32.3)\n",
            "Collecting ruamel.yaml>=0.17.0 (from pymatgen<2024.0.0,>=2023.8.10->pormake)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting spglib>=2.0.2 (from pymatgen<2024.0.0,>=2023.8.10->pormake)\n",
            "  Downloading spglib-2.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from pymatgen<2024.0.0,>=2023.8.10->pormake) (1.13.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pymatgen<2024.0.0,>=2023.8.10->pormake) (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pymatgen<2024.0.0,>=2023.8.10->pormake) (4.67.1)\n",
            "Collecting uncertainties>=3.1.4 (from pymatgen<2024.0.0,>=2023.8.10->pormake)\n",
            "  Downloading uncertainties-3.2.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pymatgen<2024.0.0,>=2023.8.10->pormake) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase<4.0.0,>=3.22.1->pormake) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase<4.0.0,>=3.22.1->pormake) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase<4.0.0,>=3.22.1->pormake) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase<4.0.0,>=3.22.1->pormake) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase<4.0.0,>=3.22.1->pormake) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase<4.0.0,>=3.22.1->pormake) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase<4.0.0,>=3.22.1->pormake) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase<4.0.0,>=3.22.1->pormake) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.5.0->pymatgen<2024.0.0,>=2023.8.10->pormake) (9.0.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.0->pymatgen<2024.0.0,>=2023.8.10->pormake)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pymatgen<2024.0.0,>=2023.8.10->pormake) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pymatgen<2024.0.0,>=2023.8.10->pormake) (2024.2)\n",
            "Requirement already satisfied: PyYAML>=3.01 in /usr/local/lib/python3.10/dist-packages (from pybtex->pymatgen<2024.0.0,>=2023.8.10->pormake) (6.0.2)\n",
            "Collecting latexcodec>=1.0.4 (from pybtex->pymatgen<2024.0.0,>=2023.8.10->pormake)\n",
            "  Downloading latexcodec-3.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pybtex->pymatgen<2024.0.0,>=2023.8.10->pormake) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pymatgen<2024.0.0,>=2023.8.10->pormake) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pymatgen<2024.0.0,>=2023.8.10->pormake) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pymatgen<2024.0.0,>=2023.8.10->pormake) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pymatgen<2024.0.0,>=2023.8.10->pormake) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->pymatgen<2024.0.0,>=2023.8.10->pormake) (1.3.0)\n",
            "Downloading pormake-0.2.2-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymatgen-2023.12.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monty-2025.1.9-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading palettable-3.3.3-py2.py3-none-any.whl (332 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spglib-2.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uncertainties-3.2.2-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading latexcodec-3.0.0-py3-none-any.whl (18 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: uncertainties, spglib, ruamel.yaml.clib, palettable, latexcodec, ruamel.yaml, pybtex, monty, pymatgen, pormake\n",
            "Successfully installed latexcodec-3.0.0 monty-2025.1.9 palettable-3.3.3 pormake-0.2.2 pybtex-0.24.0 pymatgen-2023.12.18 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 spglib-2.5.0 uncertainties-3.2.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ">>> Console logs (under WARNING level) are disabled.\n",
            "WARNING:root:File logs (under WARNING level) are disabled.\n",
            "  0%|          | 0/18 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-55.43882751464844 bcu N131 *CCC1=C(Cl)C(Cl)=C(*)C(Cl)=C1Cl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pormake/locator.py:20: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
            "  U, rmsd = scipy.spatial.transform.Rotation.align_vectors(p, q)\n",
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
            "  6%|▌         | 1/18 [00:04<01:21,  4.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 000_bcu+N131+0.cif\n",
            "-53.301849365234375 tfz-d N131 *CC1=CC(C*)=CC(CC(O)C(*)O)=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
            "\r 11%|█         | 2/18 [00:06<00:43,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 001_tfz-d+N131+1.cif\n",
            "-51.65074157714844 tfz-d N131 *CC(*)CC1=CC=C(*)C=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 3/18 [00:06<00:26,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-46.51948547363281 reo N131 *CC1=CC=CC=C1CC2=CC(*)=CC(OC)=C2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pormake/locator.py:20: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
            "  U, rmsd = scipy.spatial.transform.Rotation.align_vectors(p, q)\n",
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 002_reo+N131+3.cif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 4/18 [00:08<00:24,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-45.54187774658203 dmp N520 *CC1=C(F)C(F)=C(CC2=CC=C(*)C3=CC=CC=C23)C(F)=C1F\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pormake/locator.py:20: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
            "  U, rmsd = scipy.spatial.transform.Rotation.align_vectors(p, q)\n",
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
            "\r 28%|██▊       | 5/18 [00:09<00:21,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 003_dmp+N520+4.cif\n",
            "-43.612144470214844 reo N131 *COC1=C(I)C=C(CCCC2=CC=C(C*)C3=CC=CC=C23)C=C1I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pormake/locator.py:20: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
            "  U, rmsd = scipy.spatial.transform.Rotation.align_vectors(p, q)\n",
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 004_reo+N131+5.cif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 6/18 [00:10<00:16,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-39.686004638671875 sod N520 *COC1=CC=CC2=C(OCC3=C(Br)C(Br)=C(*)C(Br)=C3Br)C=CC=C12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pormake/locator.py:20: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
            "  U, rmsd = scipy.spatial.transform.Rotation.align_vectors(p, q)\n",
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 005_sod+N520+6.cif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 7/18 [00:12<00:16,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-36.72187042236328 bcu N431 *C1=CC(OC)=CC(C(F)(F)C(*)(F)F)=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pormake/locator.py:20: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
            "  U, rmsd = scipy.spatial.transform.Rotation.align_vectors(p, q)\n",
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 006_bcu+N431+7.cif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 8/18 [00:13<00:12,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-36.64576721191406 unc N520 *C1=CC(OC)=CC(C2=CC=C3C=C(*)C=CC3=C2)=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pormake/locator.py:20: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
            "  U, rmsd = scipy.spatial.transform.Rotation.align_vectors(p, q)\n",
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
            "\r 50%|█████     | 9/18 [00:14<00:10,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 007_unc+N520+8.cif\n",
            "-33.49506759643555 tfz-d N375 *CC1=CC(C*)=CC(CC2=CC(*)=CC(Br)=C2)=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
            "\r 56%|█████▌    | 10/18 [00:14<00:08,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 008_tfz-d+N375+9.cif\n",
            "-33.47254943847656 tfz-d N375 *CC(*)CC(O)C(*)O\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 11/18 [00:15<00:06,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-33.06509017944336 tfz-d N375 *CC1=CC(C*)=CC(CC(O)C(*)O)=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
            "\r 67%|██████▋   | 12/18 [00:16<00:05,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 009_tfz-d+N375+1.cif\n",
            "-32.67795944213867 tfz-d N331 *CC(*)CC1=CC=CC(*)=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 13/18 [00:16<00:03,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-31.042922973632812 tfz-d N375 *COC1=CC(OC*)=CC(OCC(O)C(*)O)=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
            "\r 78%|███████▊  | 14/18 [00:17<00:03,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 010_tfz-d+N375+12.cif\n",
            "-29.00395393371582 dmp N128 *CC12CC3CC(C1)CC(CC4=CC=C5C=CC(*)=CC5=C4)(C3)C2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pormake/locator.py:20: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
            "  U, rmsd = scipy.spatial.transform.Rotation.align_vectors(p, q)\n",
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 011_dmp+N128+13.cif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 15/18 [03:46<03:10, 63.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-25.928665161132812 gra N206 *CC(*)CC1=CC(*)=CC(OC)=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 16/18 [03:47<01:29, 44.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-22.633275985717773 hms N206 *CC(*)CC1=CC=CC(*)=C1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
            "\r 94%|█████████▍| 17/18 [03:49<00:31, 31.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 012_hms+N206+11.cif\n",
            "-18.136268615722656 sod N32 *COC1=CC=CC2=C(OCC#CC3=CC=C(*)C=C3)C=CC=C12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pormake/locator.py:20: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
            "  U, rmsd = scipy.spatial.transform.Rotation.align_vectors(p, q)\n",
            "<ipython-input-38-54804f6a3a8d>:200: DeprecationWarning: Please use atoms.cell.cellpar() instead\n",
            "  if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write_cif 013_sod+N32+15.cif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [03:50<00:00, 12.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: results/qkh/gen_mofs/ (stored 0%)\n",
            "  adding: results/qkh/gen_mofs/013_sod+N32+15.cif (deflated 67%)\n",
            "  adding: results/qkh/gen_mofs/000_bcu+N131+0.cif (deflated 65%)\n",
            "  adding: results/qkh/gen_mofs/007_unc+N520+8.cif (deflated 66%)\n",
            "  adding: results/qkh/gen_mofs/001_tfz-d+N131+1.cif (deflated 62%)\n",
            "  adding: results/qkh/gen_mofs/004_reo+N131+5.cif (deflated 66%)\n",
            "  adding: results/qkh/gen_mofs/005_sod+N520+6.cif (deflated 67%)\n",
            "  adding: results/qkh/gen_mofs/008_tfz-d+N375+9.cif (deflated 62%)\n",
            "  adding: results/qkh/gen_mofs/vocab_sm.json (deflated 65%)\n",
            "  adding: results/qkh/gen_mofs/003_dmp+N520+4.cif (deflated 66%)\n",
            "  adding: results/qkh/gen_mofs/006_bcu+N431+7.cif (deflated 67%)\n",
            "  adding: results/qkh/gen_mofs/011_dmp+N128+13.cif (deflated 65%)\n",
            "  adding: results/qkh/gen_mofs/010_tfz-d+N375+12.cif (deflated 62%)\n",
            "  adding: results/qkh/gen_mofs/002_reo+N131+3.cif (deflated 67%)\n",
            "  adding: results/qkh/gen_mofs/012_hms+N206+11.cif (deflated 58%)\n",
            "  adding: results/qkh/gen_mofs/009_tfz-d+N375+1.cif (deflated 62%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c6da5434-7ab4-49b5-8539-9c92d767e745\", \"qkh_Updated.zip\", 119551)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ca73fd5f-ff05-47ef-be4a-b196515ec9af\", \"data.csv\", 223)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!python run_reinforce.py with v0_qkh_round3 log_dir=test test_only=True load_path=model/reinforce/best_v0_qkh_round3.ckpt\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ase.io import read\n",
        "from ase.visualize.plot import plot_atoms\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import RDConfig\n",
        "sys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))\n",
        "import sascorer\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "plt.rcParams['font.sans-serif'] = \"Arial\"\n",
        "plt.rcParams['font.family'] = \"sans-serif\"\n",
        "plt.rcParams[\"font.size\"] = 15\n",
        "plt.rcParams[\"xtick.major.size\"] = 0\n",
        "plt.rcParams[\"ytick.major.size\"] = 0\n",
        "\n",
        "path_json = \"test/results_v0_qkh_round3_seed0_from_best_v0_qkh_round3.json\"\n",
        "\n",
        "results_optimized = json.load(open(path_json))\n",
        "ret = np.array( list(zip(*results_optimized[\"preds\"])) +\n",
        "    [\n",
        "        results_optimized[\"gen_topos\"],\n",
        "        results_optimized[\"gen_mcs\"],\n",
        "        results_optimized[\"gen_sms\"],\n",
        "    ]\n",
        ").T\n",
        "len(ret)\n",
        "\n",
        "TOTAL = 300000\n",
        "top_n = TOTAL\n",
        "ret = np.unique(ret, axis=0)\n",
        "sorted_ret = ret[np.argsort(ret[:, 0].astype(float))][:top_n]\n",
        "\n",
        "!pip install pormake\n",
        "\n",
        "import pormake as pm\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "pm.log.disable_print()\n",
        "pm.log.disable_file_print()\n",
        "\n",
        "save_dir_bb = \"results/qkh/bb_dir\"\n",
        "save_dir_gen_mofs = \"results/qkh/gen_mofs\"\n",
        "\n",
        "if os.path.exists(save_dir_bb):\n",
        "    shutil.rmtree(save_dir_bb)\n",
        "shutil.copytree(f\"{pm.__path__[0]}/database/bbs\", save_dir_bb)\n",
        "# bb_dir\n",
        "database = pm.Database(bb_dir=Path(save_dir_bb))\n",
        "# save_dir for generated MOFs\n",
        "os.makedirs(save_dir_gen_mofs, exist_ok=True)\n",
        "\n",
        "def smiles_to_xyz(smiles, save_dir, bb_name=\"tmp\"):\n",
        "    # smiles to mol\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    # mol to 3D mol\n",
        "    m = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(m)\n",
        "    AllChem.MMFFOptimizeMolecule(m)\n",
        "    # mol to molblock\n",
        "    mol_block = Chem.MolToMolBlock(m)\n",
        "    lines = mol_block.splitlines()\n",
        "    # write xyz file\n",
        "    line = lines[3]\n",
        "    num_atoms = int(line[:3])\n",
        "    num_bonds = int(line[3:6])\n",
        "\n",
        "    save_path = os.path.join(save_dir, f\"{bb_name}.xyz\")\n",
        "    with open(save_path, \"w\") as f:\n",
        "        f.write(f\"{num_atoms}\\n\")\n",
        "        f.write(f\"mol to xyz file\\n\")\n",
        "        # coords\n",
        "        for line in lines[4:4+num_atoms]:\n",
        "            tokens = line.split()\n",
        "            # change dummy atoms R to X\n",
        "            if tokens[3] == \"R\":\n",
        "                tokens[3] = \"X\"\n",
        "            f.write(f\"{tokens[3]:<10}    {tokens[0]:<10}    {tokens[1]:<10}    {tokens[2]:<10}\\n\")\n",
        "        # bonds\n",
        "        for line in lines[4+num_atoms:4+num_atoms+num_bonds]:\n",
        "            tokens = [int(line[:3]), int(line[3:6]), int(line[6:9])]\n",
        "            # bond type\n",
        "            if tokens[2] == 1:\n",
        "                bond_type = \"S\"\n",
        "            elif tokens[2] == 2:\n",
        "                bond_type = \"D\"\n",
        "            elif tokens[2] == 3:\n",
        "                bond_type = \"T\"\n",
        "            elif tokens[2] == 4:\n",
        "                bond_type = \"A\"\n",
        "            else:\n",
        "                raise Exception(\"bond type error\")\n",
        "            # find index of atom\n",
        "            idx_1 = int(tokens[0]) - 1\n",
        "            idx_2 = int(tokens[1]) - 1\n",
        "            f.write(f\"{idx_1:<10}{idx_2:<6}{bond_type:<6}\\n\")\n",
        "        f.close()\n",
        "\n",
        "\n",
        "def construct_mofs(final_ret, save_dir_bb, save_dir_gen_mofs):\n",
        "    e0 = 0 # build error\n",
        "    e1 = 0\n",
        "    e2 = 0\n",
        "    e3 = 0\n",
        "    e4 = 0\n",
        "\n",
        "    # Create a csv.writer object\n",
        "    # Write data to the CSV file\n",
        "    CIFCreate = []\n",
        "    idx = 0\n",
        "    vocab_sm = {}\n",
        "    for p, topo_, mc_, sm_ in tqdm(final_ret):\n",
        "        print(p, topo_, mc_, sm_)\n",
        "        # save smiles to xyz file\n",
        "        try:\n",
        "            if sm_ not in vocab_sm.keys():\n",
        "                smiles_to_xyz(sm_, save_dir=save_dir_bb, bb_name=f\"{len(vocab_sm)}\")\n",
        "                vocab_sm[sm_] = f\"{len(vocab_sm)}\"\n",
        "        except Exception as e:\n",
        "            e0 += 1\n",
        "            print(\"The smile of organice linker can't be converted to xyz files\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        # get topo, mc, ol\n",
        "        topo = database.get_topo(topo_)\n",
        "        mc = database.get_bb(mc_)\n",
        "        ol = database.get_bb(vocab_sm[sm_])\n",
        "\n",
        "        # check connection point matching\n",
        "        topo_cn = list(topo.unique_cn)\n",
        "        if len(topo_cn) == 1:\n",
        "            topo_cn.append(2)\n",
        "        mc_cn = mc.n_connection_points\n",
        "        ol_cn = sm_.count(\"*\")\n",
        "\n",
        "        if set(topo_cn) != set([mc_cn, ol_cn]):\n",
        "            print(f\"fail : {topo_cn, mc_cn, ol_cn}\")\n",
        "            continue\n",
        "\n",
        "        # assingn node and edge\n",
        "        if mc_cn == topo_cn[0] and topo_cn[1] == 2:\n",
        "            node_bbs = {\n",
        "                0 : mc,\n",
        "            }\n",
        "            edge_bbs = {\n",
        "                tuple(topo.unique_edge_types[0]) : ol,\n",
        "            }\n",
        "        elif mc_cn == topo_cn[0] and topo_cn[1] != 2:\n",
        "            node_bbs = {\n",
        "                0 : mc,\n",
        "                1 : ol,\n",
        "            }\n",
        "            edge_bbs = {}\n",
        "        else:\n",
        "            node_bbs = {\n",
        "                0 : ol,\n",
        "                1 : mc,\n",
        "            }\n",
        "            edge_bbs = {}\n",
        "        # build MOF\n",
        "        builder = pm.Builder()\n",
        "        try:\n",
        "            gen_mof = builder.build_by_type(topology=topo, node_bbs=node_bbs, edge_bbs=edge_bbs)\n",
        "        except Exception as e:\n",
        "            e0 += 1\n",
        "            continue\n",
        "\n",
        "        # check criterion\n",
        "        # (1) SAscore < 6\n",
        "        m = Chem.MolFromSmiles(sm_)\n",
        "        score = sascorer.calculateScore(m)\n",
        "        if score > 6:\n",
        "            e1 += 1\n",
        "            continue\n",
        "        # (2) rmsd\n",
        "        if gen_mof.info[\"max_rmsd\"] > 0.3:\n",
        "            e2 += 1\n",
        "            continue\n",
        "        # (3) # of atoms <= 3000\n",
        "        if len(gen_mof.atoms) > 3000:\n",
        "            e3 += 1\n",
        "            continue\n",
        "        # (4) length of cells < 60 A\n",
        "        if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
        "            e4 += 1\n",
        "            continue\n",
        "\n",
        "        # write cif\n",
        "        try:\n",
        "            filename = f\"{str(idx).zfill(3)}_{topo_}+{mc_}+{vocab_sm[sm_]}.cif\"\n",
        "            dataname = f\"{str(idx).zfill(3)}_{topo_}+{mc_}+{vocab_sm[sm_]}\"\n",
        "            print(f\"write_cif {filename}\")\n",
        "            gen_mof.write_cif(f\"{save_dir_gen_mofs}/{filename}\")\n",
        "            idx += 1\n",
        "\n",
        "            CIFCreate.append(dataname)\n",
        "\n",
        "        except:\n",
        "            e0 += 1\n",
        "    # write vocab for smiles of organice linker\n",
        "    json.dump(vocab_sm, open(f\"{save_dir_gen_mofs}/vocab_sm.json\", \"w\"))\n",
        "    csv_file_path = 'data.csv'\n",
        "    df = pd.DataFrame(CIFCreate)\n",
        "    df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "final_ret = sorted_ret[:TOTAL]\n",
        "construct_mofs(final_ret, save_dir_bb, save_dir_gen_mofs)\n",
        "\n",
        "!zip -r qkh_Updated.zip results/qkh/gen_mofs\n",
        "\n",
        "from google.colab import files\n",
        "files.download('qkh_Updated.zip')\n",
        "\n",
        "files.download('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''top_n = 40000\n",
        "ret = np.unique(ret, axis=0)\n",
        "sorted_ret = ret[np.argsort(ret[:, 0].astype(float))][:top_n]\n",
        "\n",
        "!pip install pormake\n",
        "\n",
        "import pormake as pm\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "pm.log.disable_print()\n",
        "pm.log.disable_file_print()\n",
        "\n",
        "save_dir_bb = \"results/qkh/bb_dir\"\n",
        "save_dir_gen_mofs = \"results/qkh/gen_mofs\"\n",
        "\n",
        "if os.path.exists(save_dir_bb):\n",
        "    shutil.rmtree(save_dir_bb)\n",
        "shutil.copytree(f\"{pm.__path__[0]}/database/bbs\", save_dir_bb)\n",
        "# bb_dir\n",
        "database = pm.Database(bb_dir=Path(save_dir_bb))\n",
        "# save_dir for generated MOFs\n",
        "os.makedirs(save_dir_gen_mofs, exist_ok=True)\n",
        "\n",
        "def smiles_to_xyz(smiles, save_dir, bb_name=\"tmp\"):\n",
        "    # smiles to mol\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    # mol to 3D mol\n",
        "    m = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(m)\n",
        "    AllChem.MMFFOptimizeMolecule(m)\n",
        "    # mol to molblock\n",
        "    mol_block = Chem.MolToMolBlock(m)\n",
        "    lines = mol_block.splitlines()\n",
        "    # write xyz file\n",
        "    line = lines[3]\n",
        "    num_atoms = int(line[:3])\n",
        "    num_bonds = int(line[3:6])\n",
        "\n",
        "    save_path = os.path.join(save_dir, f\"{bb_name}.xyz\")\n",
        "    with open(save_path, \"w\") as f:\n",
        "        f.write(f\"{num_atoms}\\n\")\n",
        "        f.write(f\"mol to xyz file\\n\")\n",
        "        # coords\n",
        "        for line in lines[4:4+num_atoms]:\n",
        "            tokens = line.split()\n",
        "            # change dummy atoms R to X\n",
        "            if tokens[3] == \"R\":\n",
        "                tokens[3] = \"X\"\n",
        "            f.write(f\"{tokens[3]:<10}    {tokens[0]:<10}    {tokens[1]:<10}    {tokens[2]:<10}\\n\")\n",
        "        # bonds\n",
        "        for line in lines[4+num_atoms:4+num_atoms+num_bonds]:\n",
        "            tokens = [int(line[:3]), int(line[3:6]), int(line[6:9])]\n",
        "            # bond type\n",
        "            if tokens[2] == 1:\n",
        "                bond_type = \"S\"\n",
        "            elif tokens[2] == 2:\n",
        "                bond_type = \"D\"\n",
        "            elif tokens[2] == 3:\n",
        "                bond_type = \"T\"\n",
        "            elif tokens[2] == 4:\n",
        "                bond_type = \"A\"\n",
        "            else:\n",
        "                raise Exception(\"bond type error\")\n",
        "            # find index of atom\n",
        "            idx_1 = int(tokens[0]) - 1\n",
        "            idx_2 = int(tokens[1]) - 1\n",
        "            f.write(f\"{idx_1:<10}{idx_2:<6}{bond_type:<6}\\n\")\n",
        "        f.close()\n",
        "\n",
        "\n",
        "def construct_mofs(final_ret, save_dir_bb, save_dir_gen_mofs):\n",
        "    e0 = 0 # build error\n",
        "    e1 = 0\n",
        "    e2 = 0\n",
        "    e3 = 0\n",
        "    e4 = 0\n",
        "\n",
        "    # Create a csv.writer object\n",
        "    # Write data to the CSV file\n",
        "    CIFCreate = []\n",
        "    idx = 0\n",
        "    vocab_sm = {}\n",
        "    for p, topo_, mc_, sm_ in tqdm(final_ret):\n",
        "        print(p, topo_, mc_, sm_)\n",
        "        # save smiles to xyz file\n",
        "        try:\n",
        "            if sm_ not in vocab_sm.keys():\n",
        "                smiles_to_xyz(sm_, save_dir=save_dir_bb, bb_name=f\"{len(vocab_sm)}\")\n",
        "                vocab_sm[sm_] = f\"{len(vocab_sm)}\"\n",
        "        except Exception as e:\n",
        "            e0 += 1\n",
        "            print(\"The smile of organice linker can't be converted to xyz files\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        # get topo, mc, ol\n",
        "        topo = database.get_topo(topo_)\n",
        "        mc = database.get_bb(mc_)\n",
        "        ol = database.get_bb(vocab_sm[sm_])\n",
        "\n",
        "        # check connection point matching\n",
        "        topo_cn = list(topo.unique_cn)\n",
        "        if len(topo_cn) == 1:\n",
        "            topo_cn.append(2)\n",
        "        mc_cn = mc.n_connection_points\n",
        "        ol_cn = sm_.count(\"*\")\n",
        "\n",
        "        if set(topo_cn) != set([mc_cn, ol_cn]):\n",
        "            print(f\"fail : {topo_cn, mc_cn, ol_cn}\")\n",
        "            continue\n",
        "\n",
        "        # assingn node and edge\n",
        "        if mc_cn == topo_cn[0] and topo_cn[1] == 2:\n",
        "            node_bbs = {\n",
        "                0 : mc,\n",
        "            }\n",
        "            edge_bbs = {\n",
        "                tuple(topo.unique_edge_types[0]) : ol,\n",
        "            }\n",
        "        elif mc_cn == topo_cn[0] and topo_cn[1] != 2:\n",
        "            node_bbs = {\n",
        "                0 : mc,\n",
        "                1 : ol,\n",
        "            }\n",
        "            edge_bbs = {}\n",
        "        else:\n",
        "            node_bbs = {\n",
        "                0 : ol,\n",
        "                1 : mc,\n",
        "            }\n",
        "            edge_bbs = {}\n",
        "        # build MOF\n",
        "        builder = pm.Builder()\n",
        "        try:\n",
        "            gen_mof = builder.build_by_type(topology=topo, node_bbs=node_bbs, edge_bbs=edge_bbs)\n",
        "        except Exception as e:\n",
        "            e0 += 1\n",
        "            continue\n",
        "\n",
        "        # check criterion\n",
        "        # (1) SAscore < 6\n",
        "        m = Chem.MolFromSmiles(sm_)\n",
        "        score = sascorer.calculateScore(m)\n",
        "        if score > 6:\n",
        "            e1 += 1\n",
        "            continue\n",
        "        # (2) rmsd\n",
        "        if gen_mof.info[\"max_rmsd\"] > 0.3:\n",
        "            e2 += 1\n",
        "            continue\n",
        "        # (3) # of atoms <= 3000\n",
        "        if len(gen_mof.atoms) > 3000:\n",
        "            e3 += 1\n",
        "            continue\n",
        "        # (4) length of cells < 60 A\n",
        "        if gen_mof.atoms.get_cell_lengths_and_angles()[:3].max() > 60:\n",
        "            e4 += 1\n",
        "            continue\n",
        "\n",
        "        # write cif\n",
        "        try:\n",
        "            filename = f\"{str(idx).zfill(3)}_{topo_}+{mc_}+{vocab_sm[sm_]}.cif\"\n",
        "            dataname = f\"{str(idx).zfill(3)}_{topo_}+{mc_}+{vocab_sm[sm_]}\"\n",
        "            print(f\"write_cif {filename}\")\n",
        "            gen_mof.write_cif(f\"{save_dir_gen_mofs}/{filename}\")\n",
        "            idx += 1\n",
        "\n",
        "            CIFCreate.append(dataname)\n",
        "\n",
        "        except:\n",
        "            e0 += 1\n",
        "    # write vocab for smiles of organice linker\n",
        "    json.dump(vocab_sm, open(f\"{save_dir_gen_mofs}/vocab_sm.json\", \"w\"))\n",
        "    csv_file_path = 'data.csv'\n",
        "    df = pd.DataFrame(CIFCreate)\n",
        "    df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "final_ret = sorted_ret[:40000]\n",
        "construct_mofs(final_ret, save_dir_bb, save_dir_gen_mofs)\n",
        "\n",
        "!zip -r qkh_Updated.zip results/qkh/gen_mofs\n",
        "\n",
        "from google.colab import files\n",
        "files.download('qkh_Updated.zip')\n",
        "\n",
        "files.download('data.csv')'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "WdRMvAuwXQBS",
        "outputId": "b3d0efa3-8a2f-4259-c1e3-bb9214a9fd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_121929/1211072864.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msorted_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pormake'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}